---
layout: post
title: Topological Data Analysis
isEditable: false
categories: [Machine Learning]
date: 2019-04-27
---

<script src="/public/post_assets/tda/d3.min.js"></script>
<script src="/public/post_assets/tda/tsne.js"></script>
<script src="/public/post_assets/tda/demo-configs.js"></script>
<!-- <script src="figure-configs.js"></script> -->
<script src="/public/post_assets/tda/visualize.js"></script>
<script src="/public/post_assets/tda/complexes.js"></script>
<script src="/public/post_assets/tda/figures.js"></script>
<link href="/public/post_assets/tda/material-icons.css" rel="stylesheet">
<link rel="stylesheet" href="/public/post_assets/tda/playground.css">
<link rel="stylesheet" href="/public/post_assets/tda/post.css">


The overall goal of Topological Data Analysis (TDA) is to be able to analyze topological features of data sets, often through computations of topological properties such as homology or via visualization. Here I will focus on the former technique, known as **persistent homology**, but I will briefly touch on the visualization aspect. Before jumping into the mathematical aspects I'll first give an overview of some motivations for TDA by both offering it as an alternative to typical statistical tools as well as showing some of the unique capabilities of TDA.

<div>
\(
   \def\R{\mathbb R}
   \def\N{\mathbb N}
   \def\X{\mathbb X}
   \def\homt{\simeq}
   \def\C{\check{C}}
   \def\e{\varepsilon}
   \def\P{\mathcal{P}}
   \require{AMScd}
   \require{extpfeil}
   \Newextarrow{\vxmapsto}{5,10}{0x21A7}
   \require{HTML}
\)
</div>

# Motivations for Understanding Topological Properties of Data

In many sciences and other fields involving data collection and analysis, one can often consider two types of data analysis: qualitative and quantitative. Given a large and potentially complex data set \\(D\\), the task of qualitative data analysis is to investigate if \\(D\\) contains information you are looking for, and this is often performed via some type of visualization. If you then feel that \\(D\\) does contain desired information, then you can often proceed to applying a more quantitative technique for extracting that information, guided by your intuition from the qualitative analysis. I claim that common statistical techniques are very useful for both tasks, but on more complex data sets currently emerging in today's sciences can be inadequate, and that a topological approach may help. Let's look at some specific examples of both qualitative and quantitative data analysis, and motivate why topological techniques might help.

## Clustering and Dimensionality Reduction

Consider an experiment in which we have a population consisting of multiple bacteria species[^bio], and we would like to determine how many different species are present. To do so we can use a technique called [Raman spectroscopy](https://en.wikipedia.org/wiki/Raman_spectroscopy), which in summary shines a laser into your sample and records a emission spectra of the sample. In this paper 4 species with 1000 bacteria each were tested with Raman spectroscopy (giving 4000 spectra) with each spectra consisting of 1500 intensity measurements for wavelengths between 500 and 3500 \\(cm^{-1}\\). Mathematically this gives us 4000 points living in \\(\R^{1500}\\). Now we want to see if the spectra can actually be used to differentiate the 4 bacteria species. Unfortunately, visualization of \\(\R^{1500}\\) directly is not helpful, as the following plot of overlapping spectra shows:

<img src="/public/post_assets/tda/spectra.png" alt="raman spectra" class="center"/>

A very standard technique for reducing this high dimensional data down to a smaller dimension is [PCA](https://en.wikipedia.org/wiki/Principal_component_analysis) (Principle Components Analysis) which finds the linear projection which maximizes the variance. Using PCA to project \\(\R^{1500}\\) to \\(\R^2\\) gives the following plot, with colors indicating the previously known species:

<img src="/public/post_assets/tda/raman_pca.png" alt="raman pca" class="center"/>

PCA has provided some useful information, but not so much as we would like. This linear projection shows that some differentiation of species using the spectra is possible, but unfortunately PCA can not be used to differentiate the blue and light blue samples as they strongly overlap. Any typical algorithm used to identify clusters (such as [k-means clustering](https://en.wikipedia.org/wiki/K-means_clustering#Standard_algorithm)) would fail to isolate 4 clusters. The original data in \\(\R^{1500}\\) probably contains the information necessary to differentiate all 4 species, but we can't visualize it well directly. On the other hand linearly projecting to a low dimension destroys the useful information we want. Projecting to a higher dimensional space like \\(\R^3\\) or using non-linear dimensionality reductions such as t-SNE [^tsne] or diffusion maps [^diff] might or might not work better, but at the end of the day can run into the same limitations. Using topology we can take a different approach: *imagine we can regard the data as a manifold \\(X \subseteq \R^{1500}\\)*; then detecting the number of different species (clusters) corresponds to determining the number of connected components of \\(X\\). Using TDA techniques we can determine the number of connected components in the original data set, *without having to project to lower-dimensions*. This type of clustering analysis is applicable to a huge number of problems, not just in the biological domain.

## Understanding Higher-Dimensional Topological Features of Primary Visual Cortex of Monkeys

However, TDA can be used for more than just inspecting connected components. One particularly interesting application of TDA to neuroscience is discussed in section 2.5 of Carlsson [^car]. In an experiment a 10x10 array of electrodes were implanted in the Primary Visual Cortex of Macaque monkeys, while the monkeys viewed either a blank screen or some movie clips. A bunch of signal processing techniques were applied to the voltage sequences, eventually resulting in a collection of data sets, each consisting of 200 data points lying in \\(\R^5\\). Each such data set \\(D_i \subseteq \R^5\\) corresponds to the monkey looking at either a blank screen or movie clips, for a 10 second window. Each point \\(p \in D_i \subseteq \R^5\\) are the 5 voltages during a 50ms window of the top 5 activated neurons in the 10 second window associated to \\(D_i\\). So we have many such \\(D_i \subseteq \R^5\\), of which some correspond to watching blank screens and others correspond to watching movie clips.

The task now is to differentiate the \\(D_i\\)'s based on blank screen vs. movie clips. Given some \\(D_i\\), *if we can view \\(D_i\\) as a topological space*, then we can apply the algebraic topology tool of homology to compute the Betti numbers of \\(D_i\\). In this study the first 3 Betti numbers \\((\beta_0, \beta_1, \beta_2)\\) were computed for each \\(D_i\\). By a vast margin the most common Betti numbers were \\(a = (1, 1, 0)\\) and \\(b = (1, 0, 1)\\), corresponding to the topology of a circle and a sphere. Finally Betti numbers were computed for data sets generated by random firings according a Poisson model (i.e. the null hypothesis). The distribution of Betti numbers is easily able to distinguish all three modes (blank screen, movie clips, random Poisson model) from each other. In addition since \\(a\\) and \\(b\\) were the most common Betti numbers for both blank screen and movie clip modes, this suggests that the primary visual cortex seems to naturally operate using the topology of circles and spheres, but the reason for this topological phenomenon is not yet known.

# Point Clouds and Simplicial Complexes

In both of the examples above and in nearly all data analysis settings one has a discrete finite data set \\(D\\). Often \\(D \subseteq \R^n\\), but more generally we consider \\(D\\) to be some discrete finite metric space (for example in comparing DNA sequences one can define a distance metric between sequences which is non-Euclidean). \\(D\\) is often called a **point cloud**. One way to look at this is that the point cloud \\(D\\) is drawn from a probability distribution with support some metric space \\(X\\). For example in the bacteria species classification experiment \\(X\\) would be the space of possible emission spectra for the 4 different species, and we would expect \\(X\\) to have 4 connected components. Thus the goal of TDA is to infer the topological properties of \\(X\\) given a point cloud \\(D\\) sampled from \\(X\\).

Since \\(D\\) is a discrete space, it is useless topologically as is. The main strategy of TDA is to build a simplicial complex from \\(D\\) such that the topological properties of the simplicial complex are similar to those of \\(X\\). Of course this isn't always possible as it is contingent upon a sufficient number of samples.

## Nerves of Open Covers and the &#268;ech Complex

The first and most natural technique for building a simplicial complex based on some topological space \\(X\\) is based on an open cover \\(\mathcal{U}\\) of \\(X\\). If \\(\mathcal{U} = \\{U_i\\}, i \in I\\) is an open cover of \\(X\\) then the simplicial complex called the **nerve of \\(\mathcal{U}\\)**, \\(N(\mathcal{U})\\), is defined to have vertex set \\(I\\), with a \\(k-1\\) simplex \\(\\{i_1, \cdots, i_k\\} \in N(\mathcal{U})\\) iff:
\\[
   U_{i_1} \cap U_{i_2} \cap \cdots \cap U_{i_k} \neq \emptyset
\\]

The following picture from Wikipedia illustrates this well:

<a title="ProboscideaRubber15 [CC BY-SA 4.0 (https://creativecommons.org/licenses/by-sa/4.0)], via Wikimedia Commons" href="https://commons.wikimedia.org/wiki/File:Constructing_nerve.png" class="center"><img width="512" alt="Constructing nerve" src="https://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Constructing_nerve.png/512px-Constructing_nerve.png"></a>

Note that if at most \\(n\\) open sets intersect simultaneously then \\(N(\mathcal{U})\\) has dimension \\(n-1\\). A basic result of nerves is the Nerve Lemma:
<div class="lemma" text="Nerve Lemma">
   Let \(X\) be a topological space, and let \(\mathcal{U}\) be an open cover of \(X\). If every non-empty intersection of open sets in \(\mathcal{U}\) is contractible, then \(N(\mathcal{U}) \homt X\).
</div>

We can now define the **&#268;ech Complex** of a finite point cloud \\(D \subseteq X\\). Let \\(\varepsilon > 0\\), and define the open cover \\(\mathcal{U} = \\{ B_\varepsilon (x) \mid x \in D \\} \\).  Then the &#268;ech Complex of radius \\(\varepsilon\\) is defined as \\(\check{C}\_\varepsilon(D) = N(\mathcal{U})\\).

## Homotopy Type of the &#268;ech Complex

To better understand the topological properties of the &#268;ech Complex we can apply the Nerve Lemma. By the Nerve Lemma, \\(\check{C}\_\varepsilon(D) \homt \bigcup_{x \in D} B\_\varepsilon(x)\\). However, what we would like is to relate the topology of \\(\C_\e(D)\\) to the topology of \\(X\\), where \\(D\\) has been sampled from \\(X\\). The following theorem[^car] is a partial result in this direction:
<div class="theorem">
   Let \(X\) be a Riemannian manifold. Then there exists an \(e\) such that for all \(\e \leq e\), there is a finite point cloud \(D \subseteq X\) such that \(\C_\e(D) \homt X\).
</div>
This theorem is a nice theoretic result, since it hints that &#268;ech Complexes of point clouds are morally the correct objects to study as they do have a topological relationship with the underlying topological space. However in terms of practicalities this theorem buys us little. The problems are the following:

   1. Since we only have access to \\(D\\) and not \\(X\\), how can we know that \\(X\\) is a Riemannian manifold?
   2. The existence of such an \\(e\\) is good, but the theorem offers no way to find or search for \\(e\\).
   3. The largest issue is that we only have one given point cloud \\(D\\), so the existence of another \\(D'\\) guaranteeing homotopy equivalence is not useful.

There have been further results that partially address some of these issues, of which Chazal[^chazal] surveys a few. An additional problem with &#268;ech Complexes is that computationally they are quite slow to compute, which leads us to consider alternate simplicial complex constructions such as the [Vietoris-Rips Complex](https://en.wikipedia.org/wiki/Vietoris–Rips_complex) and many others which are surveyed by Carlsson[^car]. However, the simplicial complex constructions are all similar in that they all attempt to reconstruct the homotopy type of \\(X\\) and can do so under strict assumptions, but in practical data analysis situations will almost always fail to be homotopy equivalent.

## Exploring Some &#268;ech Complexes

To get a better intuition for why &#268;ech Complexes of point clouds \\(D\\) sampled from a topological space \\(X\\) fail to be homotopy equivalent to \\(X\\), we can look at visualizations of &#268;ech Complexes on sample data sets. Since &#268;ech Complexes can be quite high dimensional, we only visualize the 2-skeleton of the &#268;ech Complex. Below you can interact with a variety of sample data sets, and vary the parameter \\(\varepsilon\\) to see how it affects \\(\C_\e(D)^{(2)}\\).


<div id="playground"><div id="playground-canvas"></div><div id="data-menu"></div><div id="data-details"><div id="data-controls"><div id="data-options"></div><div id="tsne-options"></div></div><div id="data-description"><span></span></div></div></div>
<script src="/public/post_assets/tda/playground.js"></script>

Play around with the &#268;ech Complex visualization as long as you want. But once you're done, here are some of the key takeaways from it.

First, due to random sampling noise and non-homogenous density it can be tricky to chose a value of \\(\e\\) such that \\(\C_\e(D) \homt X\\). For example with the annulus you have to pick some \\(\e\\) that is large enough to fill in some holes from noise, but if you pick an \\(\e\\) that is way too big then it will fill in the hole of the annulus itself. For these toy data sets we can have an intuition for what choice of \\(\e\\) "looks right", but for high dimensional data it is hard to have an understanding of a "good" choice of \\(\e\\).

Second, there can be multiple "good" choices of \\(\e\\). For example, consider the 4th data set above with 2 circles of vastly different sizes. For \\(\e \approx 0.07\\) The tiny circle obtains the correct topology, but the big circle is still disconnected. But if you try to increase \\(\e\\) so as to make the big circle connected, the tiny circle actually becomes simply connected. Both the big and tiny circles have the homotopy type of a circle, but the homotopy type of each is only visible at distinct values of \\(\e\\). In a sense \\(\e\\) is like the amount of zoom in a microscope: you can make \\(\e\\) very small to zoom in closely and inspect the topology of the tiny circle, or you can make \\(\e\\) large to zoom out and observe the topology of the big circle, at which point the tiny circle is negligible. 

The second point really provides the key insight of TDA: *There is no one best value of \\(\e\\), but rather the spectrum of topologies as \\(\e\\) varies provides a comprehensive view of the topology of the point cloud.* This will also address the first point, as the holes due to noisy sampling only last for a short range of \\(\e\\) values. Thus, in TDA we study families of simplicial complexes such as \\(\P = \\{\C_\e(D) \mid \e \in T \subseteq \R \\}\\). The crucial property of these &#268;ech Complex families is that for \\(\e \leq \e'\\) we have that \\(\C_\e(D)\\) is a subcomplex of \\(\C_{\e'}(D)\\) (this is a trivial result of the definition of a &#268;ech Complex). Also note that since point clouds are finite, only finitely many \\(\e\\) will produce distinct &#268;ech Complexes, so we can consider \\(T\\) to be finite. Other simplicial complex constructions such as Vietoris-Rips complexes also share these properties.

# Persistent Homology

## Persistence Objects

We briefly set aside the specific construction of &#268;ech Complexes and work from an algebraic perspective. Let \\((T, \leq)\\) be any partially ordered set and let \\(\underline{C}\\) be any category. We say that a **\\(T\\)-persistence object** is a family \\( \\{c_t\\}_{t \in T} \subseteq \underline{C} \\) together with a morphism \\(\phi\_{tu} : c_t \to c_u \\) whenever \\(t \leq u\\) such that if \\(t \leq u \leq v\\) then \\(\phi\_{uv} \circ \phi\_{tu} = \phi\_{tv}\\). Alternatively a \\(T\\)-persistence object can be viewed as a functor \\(\Phi : T \to \underline{C}\\). Diagrammatically this looks something like:

<div>
\[
\begin{array}{ccc}
t & \xmapsto{\Phi} & c_t \\
\style{display: inline-block; transform: rotate(90deg)}{\leq} & & \big\downarrow \; \phi_{tu} \\
u & \xmapsto{\Phi} & c_u \\
\style{display: inline-block; transform: rotate(90deg)}{\leq} & & \big\downarrow \; \phi_{uv} \\
v & \xmapsto{\Phi} & c_v 
\end{array}
\]
</div>

Suppose we have a \\(T\\)-persistence object \\( \\{c_t, \phi_{tu} \\} \\) and some partial order preserving map \\(f : T' \to T\\) for some other partially ordered set \\(T'\\). Then we have an induced \\(T'\\)-persistence object \\( \\{c_{f(t')} \\}_{t' \in T'} \\) with morphisms \\(\psi\_{t'u'} : c\_{f(t')} \to c\_{f(u')}\\) given by \\(\psi\_{t'u'} = \phi\_{f(t')f(u')}\\). It sounds more complicated than it is, so hopefully a diagram clarifies:

<div>
\[
\begin{array}{ccccc}
t' & \xmapsto{f} & t & \xmapsto{\Phi} & c_t \\
\style{display: inline-block; transform: rotate(90deg)}{\leq} & & \style{display: inline-block; transform: rotate(90deg)}{\leq} & & \big\downarrow \; \phi_{tu} \\
u' & \xmapsto{f} & u & \xmapsto{\Phi} & c_u \\
\style{display: inline-block; transform: rotate(90deg)}{\leq} & & \style{display: inline-block; transform: rotate(90deg)}{\leq} & & \big\downarrow \; \phi_{uv} \\
v' & \xmapsto{f} & v & \xmapsto{\Phi} & c_v 
\end{array}
\]
</div>

We can easily see that &#268;ech Complex families are \\(\R\\)-persistence simplicial complexes since for all \\(\e \leq \e'\\) we have the inclusion map \\(i_{\e\e'}: \C_\e(D) \hookrightarrow \C_{\e'}(D)\\) as discussed above. In addition since there are only finitely many values of \\(\e\\), say \\(E = \\{\e_1, \cdots, \e_n\\} \subseteq \R\\), which produce distinct &#268;ech Complexes, we can easily construct an order preserving map \\(f: \N \to E\\), and thus we have than a &#268;ech Complex family is an \\(\N\\)-persistence simplicial complex.

The inclusion maps \\(i_{\e\e'}: \C_\e(D) \hookrightarrow \C_{\e'}(D)\\) for an \\(\N\\)-persistence simplicial complex then induce chain maps for the simplicial chain complex \\( i_{\Delta,\e\e'}: C_p(\C_\e(D); R) \rightarrow C_p(\C_{\e'}(D); R) \\), and likewise for the simplicial homology \\( i_{*,\e\e'}: H_p(\C_\e(D); R) \rightarrow H_p(\C_{\e'}(D); R) \\) for any ring \\(R\\). Thus, we have that the homology groups \\(H_\*(\C_\e(D); R)\\) are an \\(\N\\)-persistence \\(R\\)-module. We can see this in a diagram, supposing \\(\e \leq \e'\\):

<div>
\[
\begin{array}{ccccc}
                   & \vdots \;\;\;\;\;\;  &                          & \vdots \;\;\;\;\;\;      & \\
                   & \big\downarrow \;\;\;\;\;\;   &                          & \big\downarrow \;\;\;\;\;\;      & \\
\cdots \rightarrow & H_p(\C_\e(D); R) & \xrightarrow{\partial_*} & H_{p-1}(\C_\e(D); R) & \rightarrow \cdots \\
                   & \big\downarrow \; i_{*,\e\e'}   &                          & \big\downarrow \; i_{*,\e\e'}       & \\
\cdots \rightarrow & H_p(\C_{\e'}(D); R) & \xrightarrow{\partial_*} & H_{p-1}(\C_{\e'}(D); R) & \rightarrow \cdots \\
                   & \big\downarrow \;\;\;\;\;\;   &                          & \big\downarrow \;\;\;\;\;\;      & \\
                   & \vdots \;\;\;\;\;\;  &                          & \vdots \;\;\;\;\;\;      & 
\end{array}
\]
</div>

To better understand what these inclusion induced maps are doing, we can look at a specific example from the visualization above. Consider two choices of \\(\e\\) for the annulus:

\\(\C_\e(D)\\)              |  \\(\C_{\e'}(D)\\)
:------------------------------:|:-------------------------:
![Homicide Plot](/public/post_assets/tda/annulus1.png) | ![Homicide Regression Plot](/public/post_assets/tda/annulus2.png)

In the left &#268;ech Complex there are 3 generators for \\(H_1\\), shown in red, purple and orange. If we slightly increase \\(\e\\) to \\(\e'\\) in the right &#268;ech Complex we kill the purple and orange generators, but a new green generator is born. But if we look at the image of the homomorphism induced by the inclusion we see only that purple and orange are killed, leaving only the red generator in the image.

## Classification Theorem for \\(\mathbb{N}\\)-Persistence Modules

<!-- We now consider the  -->

<!-- ## Some Easy Properties of &#268;ech Complex Families

Let \\(\P = \\{\C_\e(D) \mid \e \in T \\}\\). -->


# References

<!-- Hello!! -->

[^bio]: <a href="https://www.sciencedirect.com/science/article/pii/S0003267016300137" class="dont-break-out">https://www.sciencedirect.com/science/article/pii/S0003267016300137</a>
[^tsne]: <a href="http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf" class="dont-break-out">http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf</a>
[^diff]: <a href="https://www.sciencedirect.com/science/article/pii/S1063520306000546" class="dont-break-out">https://www.sciencedirect.com/science/article/pii/S1063520306000546</a>
[^car]: <a href="http://www.ams.org/journals/bull/2009-46-02/S0273-0979-09-01249-X/S0273-0979-09-01249-X.pdf" class="dont-break-out">http://www.ams.org/journals/bull/2009-46-02/S0273-0979-09-01249-X/S0273-0979-09-01249-X.pdf</a>
[^chazal]: <a href="https://arxiv.org/abs/1710.04019" class="dont-break-out">https://arxiv.org/abs/1710.04019</a>